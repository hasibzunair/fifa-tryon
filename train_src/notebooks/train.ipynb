{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0731d3d3-e15d-4570-b950-2f69996ef9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f23572-710c-4b45-b0b7-cdd8fa535ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "#sys.path.insert(0,\"..\")\n",
    "os.chdir('..')\n",
    "\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from options.train_options import TrainOptions\n",
    "from data.data_loader import CreateDataLoader\n",
    "from models.models import create_model\n",
    "import util.util as util\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from tensorboardX import SummaryWriter\n",
    "import cv2\n",
    "import datetime\n",
    "import ipdb\n",
    "\n",
    "from util import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed90c3b-f877-4d3b-a6a5-c5dd6f735f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10963268-54a4-4c16-817c-d8a7365025f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/uniform_all')\n",
    "SIZE=320\n",
    "NC=14\n",
    "def log(text):\n",
    "    '''Print text and save in a log file'''\n",
    "    if log_file is not None:\n",
    "        print(text, file=log_file)\n",
    "    print(text)\n",
    "    \n",
    "def generate_label_plain(inputs):\n",
    "    size = inputs.size()\n",
    "    pred_batch = []\n",
    "    for input in inputs:\n",
    "        input = input.view(1, NC, 256,192)\n",
    "        pred = np.squeeze(input.data.max(1)[1].cpu().numpy(), axis=0)\n",
    "        pred_batch.append(pred)\n",
    "\n",
    "    pred_batch = np.array(pred_batch)\n",
    "    pred_batch = torch.from_numpy(pred_batch)\n",
    "    label_batch = pred_batch.view(size[0], 1, 256,192)\n",
    "\n",
    "    return label_batch\n",
    "\n",
    "def morpho(mask,iter):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    new=[]\n",
    "    for i in range(len(mask)):\n",
    "        tem=mask[i].squeeze().reshape(256,192,1)*255\n",
    "        tem=tem.astype(np.uint8)\n",
    "        tem=cv2.dilate(tem,kernel,iterations=iter)\n",
    "        tem=tem.astype(np.float64)\n",
    "        tem=tem.reshape(1,256,192)\n",
    "        new.append(tem.astype(np.float64)/255.0)\n",
    "    new=np.stack(new)\n",
    "    return new\n",
    "\n",
    "def generate_label_color(inputs):\n",
    "    label_batch = []\n",
    "    for i in range(len(inputs)):\n",
    "        label_batch.append(util.tensor2label(inputs[i], opt.label_nc))\n",
    "    label_batch = np.array(label_batch)\n",
    "    label_batch = label_batch * 2 - 1\n",
    "    input_label = torch.from_numpy(label_batch)\n",
    "\n",
    "    return input_label\n",
    "\n",
    "def complete_compose(img,mask,label):\n",
    "    label=label.cpu().numpy()\n",
    "    M_f=label>0\n",
    "    M_f=M_f.astype(np.int)\n",
    "    M_f=torch.FloatTensor(M_f).cuda()\n",
    "    masked_img=img*(1-mask)\n",
    "    M_c=(1-mask.cuda())*M_f\n",
    "    M_c=M_c+torch.zeros(img.shape).cuda()##broadcasting\n",
    "    return masked_img,M_c,M_f\n",
    "\n",
    "def compose(label,mask,color_mask,edge,color,noise):\n",
    "    # check=check>0\n",
    "    # print(check)\n",
    "    masked_label=label*(1-mask)\n",
    "    masked_edge=mask*edge\n",
    "    masked_color_strokes=mask*(1-color_mask)*color\n",
    "    masked_noise=mask*noise\n",
    "    return masked_label,masked_edge,masked_color_strokes,masked_noise\n",
    "\n",
    "def changearm(old_label):\n",
    "    label=old_label\n",
    "    arm1=torch.FloatTensor((data['label'].cpu().numpy()==11).astype(np.int))\n",
    "    arm2=torch.FloatTensor((data['label'].cpu().numpy()==13).astype(np.int))\n",
    "    noise=torch.FloatTensor((data['label'].cpu().numpy()==7).astype(np.int))\n",
    "    label=label*(1-arm1)+arm1*4\n",
    "    label=label*(1-arm2)+arm2*4\n",
    "    label=label*(1-noise)+noise*4\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f9fe03-7f25-4974-a361-768e2c304c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('sample',exist_ok=True)\n",
    "opt = TrainOptions().parse()\n",
    "\n",
    "# Change to run on notebook\n",
    "#opt.dataroot = \"../datasets/acgpn_data/try_on_training/\"\n",
    "\n",
    "opt.name = \"trainer_test\"\n",
    "util.mkdirs(os.path.join(opt.checkpoints_dir, opt.name))\n",
    "\n",
    "iter_path = os.path.join(opt.checkpoints_dir, opt.name, 'iter.txt')\n",
    "log_path = os.path.join(opt.checkpoints_dir, opt.name, 'log.txt')\n",
    "log_file = open(log_path, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be6a4d5-d207-4678-b657-cb80505dd72b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeca58b-514d-4beb-ab58-e3a5e5893b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.dataroot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29893871-cddc-44a9-aa62-e854ef5ab1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4fc385-40ce-4ab8-ae0c-f0675f6342e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.continue_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886ad176-3e6f-4aad-bd2c-c5adb50f4a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f70ebd-d47a-44ca-b3c7-5b685050576f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a080d69f-3790-4f79-93bc-4b8d220d7f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt.continue_train:\n",
    "    try:\n",
    "        start_epoch, epoch_iter = np.loadtxt(iter_path , delimiter=',', dtype=int)\n",
    "    except:\n",
    "        start_epoch, epoch_iter = 1, 0\n",
    "    log('Resuming from epoch %d at iteration %d' % (start_epoch, epoch_iter))        \n",
    "else:    \n",
    "    start_epoch, epoch_iter = 1, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617767d9-4a66-486f-84f5-645583c84f45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bec2e77-0516-46dc-a0e8-e379f8d62f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch, epoch_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63433301-b707-4816-a901-02d76c3326f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt.debug:\n",
    "    opt.display_freq = 1\n",
    "    opt.print_freq = 1\n",
    "    opt.niter = 1\n",
    "    opt.niter_decay = 0\n",
    "    opt.max_dataset_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78449a53-0d06-43b2-9122-a21b79145861",
   "metadata": {},
   "source": [
    "## Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2548b5ab-6f9a-4e30-a866-eda369e7b0f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f4d02a-bd01-4278-b9a1-fa0956c74d31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cfca2e-7203-4358-ac90-3cfc36cae37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = CreateDataLoader(opt)\n",
    "dataset = data_loader.load_data()\n",
    "dataset_size = len(data_loader)\n",
    "log('#training images = %d' % dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e20d6a-da65-4ade-9716-21e92d759899",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b357131-bf0d-4028-b1a7-7caf430a649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9791a68-b19d-4b04-becc-686b5c736358",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e242b3-2e79-4b85-b048-ddcd13871fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d085ee-1edf-464d-b12a-29bd54730b54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ad57d7b-33eb-4891-9db2-c9c00fd685c4",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c81ae69-6fe1-47db-a7b2-1a7e37dd24f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "model = create_model(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6004b4e6-872c-4418-b085-8026794e97cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.use_gan_feat_loss, opt.use_vgg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d66e9e2-135c-4948-964a-cc3b3d774c05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd07aca0-e725-4011-abfc-16a7e3331812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f53cfde-0efd-4607-97e0-367fdb4515af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a53937b-2cb4-41b2-b33d-b6c51bd01ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b22f002-bcb2-46ee-9c52-6fdecff6a31b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067ab6a4-ec22-4be9-851e-f772f478a1de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eaaee7-ea3b-45b9-8bc1-d219da86e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_steps = (start_epoch-1) * dataset_size + epoch_iter\n",
    "\n",
    "# display_delta = total_steps % opt.display_freq\n",
    "# print_delta = total_steps % opt.print_freq\n",
    "# save_delta = total_steps % opt.save_latest_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc439e95-e74d-48df-9e39-02ce17043a77",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91619333-9081-4a20-a07d-085e086c40c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step = 0\n",
    "# from IPython.core.debugger import set_trace; set_trace()\n",
    "# step_per_batch = dataset_size / opt.batchSize\n",
    "# for epoch in range(start_epoch, opt.niter + opt.niter_decay + 1):\n",
    "#     epoch_start_time = time.time()\n",
    "#     if epoch != start_epoch:\n",
    "#         epoch_iter = epoch_iter % dataset_size\n",
    "\n",
    "#     for i, data in enumerate(dataset, start=epoch_iter):\n",
    "#         iter_start_time = time.time()\n",
    "\n",
    "#         total_steps += opt.batchSize\n",
    "#         epoch_iter += opt.batchSize\n",
    "\n",
    "#         # whether to collect output images\n",
    "#         #save_fake = total_steps % opt.display_freq == display_delta\n",
    "#         save_fake = True\n",
    "\n",
    "#         ##add gaussian noise channel && wash the label\n",
    "#         t_mask=torch.FloatTensor((data['label'].cpu().numpy()==7).astype(np.float))\n",
    "#         data['label']=data['label']*(1-t_mask)+t_mask*4\n",
    "#         mask_clothes=torch.FloatTensor((data['label'].cpu().numpy()==4).astype(np.int))\n",
    "#         mask_fore=torch.FloatTensor((data['label'].cpu().numpy()>0).astype(np.int))\n",
    "#         img_fore=data['image']*mask_fore\n",
    "#         img_fore_wc=img_fore*mask_fore\n",
    "#         all_clothes_label=changearm(data['label'])\n",
    "#         ############## Forward Pass ######################\n",
    "#         losses, fake_image, real_image,input_label,L1_loss,style_loss,clothes_mask,warped,refined,CE_loss,rx,ry,cx,cy,rg,cg= model(Variable(data['label'].cuda()),Variable(data['edge'].cuda()),Variable(img_fore.cuda()),Variable(mask_clothes.cuda()),Variable(data['color'].cuda()),Variable(all_clothes_label.cuda()),Variable(data['image'].cuda()),Variable(data['pose'].cuda()),Variable(data['mask'].cuda())  )\n",
    "\n",
    "#         # sum per device losses\n",
    "#         losses = [ torch.mean(x) if not isinstance(x, int) else x for x in losses ]\n",
    "#         loss_dict = dict(zip(model.module.loss_names, losses))\n",
    "\n",
    "#         # calculate final loss scalar\n",
    "#         loss_D = (loss_dict['D_fake'] + loss_dict['D_real']) * 0.5\n",
    "#         loss_G = loss_dict['G_GAN']+loss_dict.get('G_GAN_Feat',0)+loss_dict.get('G_VGG',0)+torch.mean(L1_loss+CE_loss+rx+ry+cx+cy+rg+cg)\n",
    "\n",
    "#         writer.add_scalar('loss_d', loss_D, step)\n",
    "#         writer.add_scalar('loss_g', loss_G, step)\n",
    "#         writer.add_scalar('loss_L1', torch.mean(L1_loss), step)\n",
    "#         writer.add_scalar('CE_loss', torch.mean(CE_loss), step)\n",
    "#         writer.add_scalar('rx', torch.mean(rx), step)\n",
    "#         writer.add_scalar('ry', torch.mean(ry), step)\n",
    "#         writer.add_scalar('cx', torch.mean(cx), step)\n",
    "#         writer.add_scalar('cy', torch.mean(cy), step)\n",
    "\n",
    "#         writer.add_scalar('loss_g_gan', loss_dict['G_GAN'], step)\n",
    "#         writer.add_scalar('loss_g_gan_feat', loss_dict['G_GAN_Feat'], step)\n",
    "#         writer.add_scalar('loss_g_vgg', loss_dict['G_VGG'], step)\n",
    "\n",
    "#         ############### Backward Pass ####################\n",
    "#         # update generator weights\n",
    "#         model.module.optimizer_G.zero_grad()\n",
    "#         loss_G.backward()\n",
    "#         model.module.optimizer_G.step()\n",
    "#         #\n",
    "#         # # update discriminator weights\n",
    "#         model.module.optimizer_D.zero_grad()\n",
    "#         loss_D.backward()\n",
    "#         model.module.optimizer_D.step()\n",
    "\n",
    "#         ############## Display results and errors ##########\n",
    "\n",
    "\n",
    "#         ### display output images\n",
    "#         if step % 100 == 0:\n",
    "#             a = generate_label_color(generate_label_plain(input_label)).float().cuda()\n",
    "#             b = real_image.float().cuda()\n",
    "#             c = fake_image.float().cuda()\n",
    "#             d=torch.cat([clothes_mask,clothes_mask,clothes_mask],1)\n",
    "#             e=warped\n",
    "#             f=refined\n",
    "#             combine = torch.cat([a[0],b[0],c[0],d[0],e[0],f[0]], 2).squeeze()\n",
    "#             cv_img=(combine.permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "#             writer.add_image('combine', (combine.data + 1) / 2.0, step)\n",
    "#             rgb=(cv_img*255).astype(np.uint8)\n",
    "#             bgr=cv2.cvtColor(rgb,cv2.COLOR_RGB2BGR)\n",
    "#             cv2.imwrite('sample/test'+str(step)+'.jpg',bgr)\n",
    "\n",
    "#         step += 1\n",
    "#         iter_end_time = time.time()\n",
    "#         iter_delta_time = iter_end_time - iter_start_time\n",
    "#         step_delta = (step_per_batch-step%step_per_batch) + step_per_batch*(opt.niter + opt.niter_decay-epoch)\n",
    "#         eta = iter_delta_time*step_delta\n",
    "#         eta = str(datetime.timedelta(seconds=int(eta)))\n",
    "#         time_stamp = datetime.datetime.now()\n",
    "#         now = time_stamp.strftime('%Y.%m.%d-%H:%M:%S')\n",
    "#         #print('{}:{}:[step-{}]--[loss_G-{:.6f}]--[loss_D-{:.6f}]--[ETA-{}]-[rx{}]-[ry{}]-[cx{}]-[cy{}]-[rg{}]-[cg{}]'.format(now,epoch_iter,step, loss_G, loss_D, eta,rx,ry,cx,cy,rg,cg))\n",
    "#         log('{}:{}:[step-{}]--[loss_G-{:.6f}]--[loss_D-{:.6f}]--[ETA-{}]'.format(now,epoch_iter,step, loss_G,loss_D, eta))\n",
    "\n",
    "#         ### save latest model\n",
    "#         if total_steps % opt.save_latest_freq == save_delta:\n",
    "#             log('saving the latest model (epoch %d, total_steps %d)' % (epoch, total_steps))\n",
    "#             model.module.save('latest')\n",
    "#             np.savetxt(iter_path, (epoch, epoch_iter), delimiter=',', fmt='%d')\n",
    "\n",
    "#         # subsample dataset\n",
    "#         # for full data use 'dataset_size'\n",
    "#         if epoch_iter >= 5000:\n",
    "#             break\n",
    "\n",
    "#     # end of epoch \n",
    "#     iter_end_time = time.time()\n",
    "#     log('End of epoch %d / %d \\t Time Taken: %d sec' %\n",
    "#           (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\n",
    "\n",
    "#     ### save model for this epoch\n",
    "#     if epoch % opt.save_epoch_freq == 0:\n",
    "#         log('saving the model at the end of epoch %d, iters %d' % (epoch, total_steps))        \n",
    "#         model.module.save('latest')\n",
    "#         model.module.save(epoch)\n",
    "#         np.savetxt(iter_path, (epoch + 1, 0), delimiter=',', fmt='%d')\n",
    "\n",
    "#     ### instead of only training the local enhancer, train the entire network after certain iterations\n",
    "#     if (opt.niter_fix_global != 0) and (epoch == opt.niter_fix_global):\n",
    "#         model.module.update_fixed_params()\n",
    "\n",
    "#     ### linearly decay learning rate after certain iterations\n",
    "#     if epoch > opt.niter:\n",
    "#         model.module.update_learning_rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b674c69-0f9d-49b0-869d-7a9a226b7e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac06893-3f4e-43cf-becc-35cbddae35ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
